{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eba2bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from src.nn.nn_dataset import DataSampler\n",
    "from src.ode.sm_models_d import SynchronousMachineModels\n",
    "from src.nn.nn_actions import NeuralNetworkActions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f091fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Device detection\n",
    "def detect_device():\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    return device\n",
    "\n",
    "\n",
    "device = detect_device()\n",
    "\n",
    "# Load configuration and apply overrides for fast debugging\n",
    "cfg = OmegaConf.load(\"src/conf/setup_dataset_nn.yaml\")\n",
    "\n",
    "# Debug-friendly settings\n",
    "cfg.nn.type = \"DynamicNN\"\n",
    "cfg.nn.lr = 1e-3\n",
    "cfg.nn.num_epochs = 20\n",
    "cfg.nn.early_stopping = False\n",
    "\n",
    "# Reduce dataset size for quick tests\n",
    "cfg.dataset.perc_of_data_points = 0.05\n",
    "cfg.dataset.perc_of_col_points = 0.05\n",
    "\n",
    "# Weighting scheme being tested\n",
    "cfg.nn.weighting.update_weights_freq = 5\n",
    "cfg.nn.weighting.update_weight_method = \"Static\"   # or \"Static\", \"ID\", \"DN\", \"WB\", \"Sam\"\n",
    "\n",
    "# Dataset path\n",
    "dataset_path = \"data/SM_AVR_GOV/dataset_set5_mixed.pkl\"\n",
    "assert os.path.exists(dataset_path), f\"Missing dataset: {dataset_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b810fbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SM_AVR_GOV data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonaswiendl/local/02456_DeepLearning/src/nn/nn_dataset.py:186: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:264.)\n",
      "  training_sample = torch.tensor(training_sample, dtype=torch.float32) # convert the trajectory to tensor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  800000 Number of validation samples:  100000 Number of testing samples:  100000\n",
      "Number of different initial conditions for collocation points:  100\n",
      "['theta', 'omega', 'E_d_dash', 'E_q_dash', 'R_F', 'V_r', 'E_fd', 'P_sv', 'P_m'] Variables\n",
      "[[-2, 2], [-1, 1], [0], [1], [1], [1.105], [1.08], [0.7048], [0.7048]] Set of values for init conditions\n",
      "[10, 10, 1, 1, 1, 1, 1, 1, 1] Iterations per value\n",
      "Selected deep learning model:  DynamicNN\n",
      "Number of labeled training data: 40000 Number of collocation points: 5000 Number of collocation points (IC): 100 Number of validation data: 100000\n",
      "Weights initialized as:  [1, 0.001, 0.0001, 0.001]  are updated with scheme:  Static \n",
      "getting in training\n",
      "Model( and tf values) saved: model/data_dt_pinn_ic/SM_AVR_GOVDynamicNN_1_20_40000_5000_100000_None_None_1_0.001_0.0001_0.001_Static.pth\n",
      "Total test trajectories 100\n",
      "Loss: 0.00244825\n",
      "MAE Loss: 0.02837128\n",
      "Total trainable parameters 17929\n",
      "\n",
      "Training completed.\n",
      "Final total loss: 6.5812e-03\n",
      "Data loss:        1.9911e-03\n",
      "dt loss:          4.4477e+00\n",
      "PINN loss:        5.7097e-01\n",
      "IC loss:          8.5243e-02\n"
     ]
    }
   ],
   "source": [
    "# Load data + model physics\n",
    "ds = DataSampler(cfg, dataset_path=dataset_path)\n",
    "modelling_full = SynchronousMachineModels(cfg)\n",
    "\n",
    "# Create NeuralNetworkActions instance\n",
    "net = NeuralNetworkActions(cfg, modelling_full, data_loader=ds)\n",
    "# Call pinn_train2 EXACTLY how it was designed\n",
    "net.pinn_train2(\n",
    "    num_of_skip_data_points=1,\n",
    "    num_of_skip_col_points=1,      # correct for new code\n",
    "    num_of_skip_val_points=1,\n",
    "    wandb_run=None,\n",
    ")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nTraining completed.\")\n",
    "print(f\"Final total loss: {net.loss_total.item():.4e}\")\n",
    "print(f\"Data loss:        {net.loss_data.item():.4e}\")\n",
    "print(f\"dt loss:          {net.loss_dt.item():.4e}\")\n",
    "print(f\"PINN loss:        {net.loss_pinn.item():.4e}\")\n",
    "print(f\"IC loss:          {net.loss_pinn_ic.item():.4e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13c2d51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinn_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
